// app/api/generate-subtitles/route.ts
import { NextRequest, NextResponse } from "next/server";
import { join } from "path";
import { writeFile, mkdir, unlink, readFile } from "fs/promises";
import { existsSync } from "fs";
import { v4 as uuidv4 } from "uuid";
import os from "os";
import ffmpeg from "fluent-ffmpeg";
import ffmpegStatic from "ffmpeg-static";
import ffprobeStatic from "ffprobe-static";
import OpenAI from "openai";

// è¨­ç½® ffmpeg å’Œ ffprobe è·¯å¾‘
ffmpeg.setFfmpegPath(ffmpegStatic as string);
ffmpeg.setFfprobePath(ffprobeStatic.path);

// åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY, // ç¢ºä¿åœ¨ .env.local ä¸­è¨­ç½®
});

export async function POST(request: NextRequest) {
  try {
    // è§£æè¡¨å–®è³‡æ–™
    const formData = await request.formData();
    const videoFile = formData.get("video") as File;

    if (!videoFile) {
      return NextResponse.json(
        { success: false, error: "æœªæ‰¾åˆ°è¦–é »æ–‡ä»¶" },
        { status: 400 }
      );
    }

    // å‰µå»ºè‡¨æ™‚æ–‡ä»¶å¤¾
    const tempDir = join(os.tmpdir(), "video-processing");
    if (!existsSync(tempDir)) {
      await mkdir(tempDir, { recursive: true });
    }

    // ç”Ÿæˆå”¯ä¸€IDä½œç‚ºæ–‡ä»¶å
    const sessionId = uuidv4();
    const inputPath = join(tempDir, `${sessionId}-input.mp4`);
    const outputPath = join(tempDir, `${sessionId}-output.wav`);

    // å°‡ä¸Šå‚³çš„æ–‡ä»¶å¯«å…¥è‡¨æ™‚æ–‡ä»¶
    const buffer = Buffer.from(await videoFile.arrayBuffer());
    await writeFile(inputPath, buffer);

    console.log("âœ… è¦–é »æ–‡ä»¶å·²ä¿å­˜åˆ°:", inputPath);

    // æå–éŸ³é »
    await new Promise<void>((resolve, reject) => {
      ffmpeg(inputPath)
        .noVideo()
        .audioCodec("pcm_s16le")
        .audioFrequency(16000)
        .audioChannels(1)
        .on("error", (err) => {
          console.error("âŒ FFmpeg éŒ¯èª¤:", err);
          reject(err);
        })
        .on("end", () => {
          console.log("âœ… éŸ³é »æå–å®Œæˆ");
          resolve();
        })
        .save(outputPath);
    });

    // è®€å–éŸ³é »æ–‡ä»¶
    const audioData = await readFile(outputPath);

    // èª¿ç”¨ Whisper API é€²è¡Œè½‰éŒ„
    console.log("ğŸ”Š é–‹å§‹ä½¿ç”¨ Whisper è½‰éŒ„...");
    const transcription = await openai.audio.transcriptions.create({
      file: new File([audioData], `${sessionId}.wav`, { type: "audio/wav" }),
      model: "whisper-1",
      response_format: "verbose_json", // ç²å–è©³ç´°çš„æ™‚é–“æˆ³ä¿¡æ¯
    });

    console.log("âœ… Whisper è½‰éŒ„å®Œæˆ");

    // æå–å­—å¹•æ•¸æ“š
    // æ³¨æ„ï¼šå›å‚³é¡å‹å¯èƒ½éœ€è¦æ ¹æ“šå¯¦éš› API èª¿æ•´
    const subtitles =
      (transcription as any).segments?.map((segment: any) => ({
        start: segment.start,
        end: segment.end,
        text: segment.text,
      })) || [];

    // ç”Ÿæˆ WebVTT æ ¼å¼å­—å¹•
    const vttContent = generateWebVTT(subtitles);

    // ç”Ÿæˆ SRT æ ¼å¼å­—å¹•
    const srtContent = generateSRT(subtitles);

    // æ¸…ç†è‡¨æ™‚æ–‡ä»¶
    try {
      await unlink(inputPath);
      await unlink(outputPath);
      console.log("âœ… è‡¨æ™‚æ–‡ä»¶å·²æ¸…ç†");
    } catch (e) {
      console.warn("âš ï¸ æ¸…ç†è‡¨æ™‚æ–‡ä»¶æ™‚å‡ºéŒ¯:", e);
    }

    // è¿”å›çµæœ
    return NextResponse.json({
      success: true,
      transcript: (transcription as any).text,
      subtitles,
      vtt: vttContent,
      srt: srtContent,
    });
  } catch (error) {
    console.error("âŒ è™•ç†å¤±æ•—:", error);
    return NextResponse.json(
      {
        success: false,
        error: `è™•ç†è¦–é »æ™‚å‡ºéŒ¯: ${
          error instanceof Error ? error.message : String(error)
        }`,
      },
      { status: 500 }
    );
  }
}

// ç”Ÿæˆ WebVTT æ ¼å¼å­—å¹•
function generateWebVTT(
  subtitles: Array<{ start: number; end: number; text: string }>
) {
  let vtt = "WEBVTT\n\n";

  subtitles.forEach((sub, index) => {
    const startTime = formatVTTTime(sub.start);
    const endTime = formatVTTTime(sub.end);

    vtt += `${index + 1}\n`;
    vtt += `${startTime} --> ${endTime}\n`;
    vtt += `${sub.text}\n\n`;
  });

  return vtt;
}

// ç”Ÿæˆ SRT æ ¼å¼å­—å¹•
function generateSRT(
  subtitles: Array<{ start: number; end: number; text: string }>
) {
  let srt = "";

  subtitles.forEach((sub, index) => {
    const startTime = formatSRTTime(sub.start);
    const endTime = formatSRTTime(sub.end);

    srt += `${index + 1}\n`;
    srt += `${startTime} --> ${endTime}\n`;
    srt += `${sub.text}\n\n`;
  });

  return srt;
}

// æ ¼å¼åŒ–æ™‚é–“ç‚º VTT æ ¼å¼ (HH:MM:SS.mmm)
function formatVTTTime(seconds: number) {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const ms = Math.floor((seconds - Math.floor(seconds)) * 1000);

  return `${hours.toString().padStart(2, "0")}:${minutes
    .toString()
    .padStart(2, "0")}:${secs.toString().padStart(2, "0")}.${ms
    .toString()
    .padStart(3, "0")}`;
}

// æ ¼å¼åŒ–æ™‚é–“ç‚º SRT æ ¼å¼ (HH:MM:SS,mmm)
function formatSRTTime(seconds: number) {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const ms = Math.floor((seconds - Math.floor(seconds)) * 1000);

  return `${hours.toString().padStart(2, "0")}:${minutes
    .toString()
    .padStart(2, "0")}:${secs.toString().padStart(2, "0")},${ms
    .toString()
    .padStart(3, "0")}`;
}
