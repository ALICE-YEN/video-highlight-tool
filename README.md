# ğŸ“¹ Video Highlight Tool

This project is a **Next.js-based video highlight editing tool**. It allows users to **upload a video**, automatically **generate transcripts**, and **select highlight segments** for a summarized playback.

**Live Demo**: [Your Deployed URL]  


## ğŸ› ï¸ Tech Stack

| Category      | Technology           | Purpose                                      |
|--------------|----------------------|----------------------------------------------|
| **Frontend** | ![Next.js](https://img.shields.io/badge/Next.js-000?logo=next.js&logoColor=white)  | Supports SSR, SSG, CSR, and ISR |
|              | ![TailwindCSS](https://img.shields.io/badge/TailwindCSS-06B6D4?logo=tailwindcss&logoColor=white)  | Utility-first CSS framework |
|              | ![Framer Motion](https://img.shields.io/badge/Framer_Motion-0055FF?logo=framer&logoColor=white)  | Animation library for smooth UI interactions |
|              | ![React Context](https://img.shields.io/badge/React_Context-61DAFB?logo=react&logoColor=white)  | Global state management |
| **Backend**  | ![Next.js API Routes](https://img.shields.io/badge/Next.js_API-000?logo=next.js&logoColor=white)  | Backend framework for handling API requests |
| **AI**       | ![OpenAI Whisper](https://img.shields.io/badge/Whisper_API-412991?logo=openai&logoColor=white)  | AI service for audio transcription |
|              | ![OpenAI GPT](https://img.shields.io/badge/OpenAI_GPT-412991?logo=openai&logoColor=white)  | AI service for title generation and selecting highlight sentences |
| **Video**    | ![FFmpeg](https://img.shields.io/badge/FFmpeg-007808?logo=ffmpeg&logoColor=white) | Video processing tool for extracting  |


## ğŸ“Œ Features

### ğŸ¥ 1. Video Upload
- Users can upload a video file.
- The backend extracts audio and sends it to OpenAI Whisper for transcription.

### ğŸ“ 2. Automatic AI Processing
- Uses OpenAI Whisper to generate **full video transcripts**.
- GPT API processes the transcript into **sections with titles**.
- The tool automatically suggests **highlighted sentences**.

### âœ‚ï¸ 3. Video Highlight Editing
- Two playback modes: **"Original"** (full video) and **"Highlighted"** (skips unselected parts).
- Users can manually **select/unselect** highlight sentences.
- The timeline visually represents selected highlights.
- The video player **automatically updates preview content** when sentences are selected/unselected.

### ğŸ¬ 4. Interactive Transcript Editing
- Clicking on a timestamp **jumps to the corresponding moment** in the video.
- The transcript area **auto-scrolls** to keep the current sentence visible.
- Users can **edit subtitles and section titles** directly in the transcript.
- Edited subtitles are dynamically updated in the video.

### ğŸ”¤ 5. Subtitle Display
- The video player supports **real-time subtitles**.
- Users can **adjust subtitle font size** for better readability.

## ğŸš€ Installation & Setup

#### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/ALICE-YEN/video-highlight-tool.git
cd video-highlight-tool
```

#### 2ï¸âƒ£ Install Dependencies
```bash
pnpm install
```

#### 3ï¸âƒ£ Start the Development Server
```bash
pnpm dev
```


## Next.js API Workflow
- **For a detailed overview of the Next.js API Workflow for Video & AI Transcription, refer to the Sequence Diagram (`NextJS_Whisper_Flow.wsd`).**
![image](https://github.com/user-attachments/assets/20b59951-fe1d-4663-84ad-cce86058c6c7)


## âš–ï¸ Technical Choices  

### ğŸï¸ FFmpeg Processing Options  

| Option | Evaluation | Pros | Cons | Constraints (Cost, Deployment, etc.) | Final Choice |
|--------|------------|------|------|------------------------------------|--------------|
| **Standalone Backend** | Run FFmpeg on a dedicated backend server (e.g., AWS Lambda, GCP, or a dedicated server) | âœ… High performance for large videos <br> âœ… Can handle multiple concurrent requests | âŒ Requires backend server maintenance <br> âŒ Higher cost for dedicated resources | Higher server costs, but scalable | âŒ Not chosen |
| **FFmpeg on Next.js Backend (FFmpeg on Node.js)** | Utilize Next.js API routes with `fluent-ffmpeg` to process video/audio | âœ… Simplifies deployment using Vercel functions <br> âœ… Lower cost than a dedicated backend <br> âœ… Easier to integrate with the app | âŒ Limited performance for large files <br> âŒ Could hit memory limits on serverless environments | Works well within Vercelâ€™s serverless limits for audio extraction | âœ… **Chosen** |
| **FFmpeg in Browser (WASM-based FFmpeg)** | Process video/audio in the browser using `ffmpeg.wasm` | âœ… No backend infrastructure needed <br> âœ… Lower server costs <br> âœ… Fully client-side execution | âŒ Poor performance for large files <br> âŒ High CPU usage on client devices | Limited by userâ€™s device performance | âŒ Not chosen |

**Final Decision:**  
ğŸ“Œ **FFmpeg on Next.js Backend (FFmpeg on Node.js)** was chosen because it **strikes a balance between cost-efficiency and ease of deployment** while working well within **Vercelâ€™s serverless function constraints** for **audio extraction**.



### ğŸ—£ï¸ Whisper Speech-to-Text Options  

| Option | Evaluation | Pros | Cons | Constraints (Cost, Deployment, etc.) | Final Choice |
|--------|------------|------|------|------------------------------------|--------------|
| **@xenova/whisper in Browser** | Runs Whisper speech-to-text **entirely in the frontend** using WebAssembly (WASM) | âœ… No backend cost <br> âœ… Runs offline <br> âœ… No API latency | âŒ High CPU/RAM usage <br> âŒ Poor performance on mobile devices <br> âŒ Large model downloads (~100MB+) | Requires powerful client devices to work efficiently | âŒ Not chosen |
| **@xenova/whisper on Backend (Node.js)** | Runs Whisper **on Next.js API routes** using Node.js | âœ… No OpenAI API cost <br> âœ… Runs within our own backend <br> âœ… No request limits | âŒ Slower inference compared to OpenAI API <br> âŒ High resource usage for large files | Requires dedicated compute resources | âŒ Not chosen |
| **OpenAI Whisper API** | Uses OpenAIâ€™s hosted Whisper API for speech-to-text conversion | âœ… Fast inference times <br> âœ… No resource constraints <br> âœ… No model management required | âŒ API cost per request <br> âŒ Requires external API call (latency) | Pay-per-use pricing, but low effort to maintain | âœ… **Chosen** |

**Final Decision:**  
ğŸ“Œ **OpenAI Whisper API** was chosen because it provides **fast, reliable speech-to-text processing** without the need to manage our own machine learning models or dedicate resources to **hosting** a Whisper instance.










## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
